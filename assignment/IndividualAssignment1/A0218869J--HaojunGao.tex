\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for grffile with XeLaTeX
    \def\Gread@@xetex#1{%
      \IfFileExists{"\Gin@base".bb}%
      {\Gread@eps{\Gin@base.bb}}%
      {\Gread@@xetex@aux#1}%
    }
    \makeatother

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{A0218869J--HaojunGao}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        \ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{individual-assignment-1}{%
\section{Individual Assignment 1}\label{individual-assignment-1}}

\hypertarget{due-on-aug-25-1159pm}{%
\paragraph{(Due on Aug 25 11:59PM)}\label{due-on-aug-25-1159pm}}

    \hypertarget{part-i-simulation}{%
\subsection{Part I: Simulation}\label{part-i-simulation}}

In this exercise, we will use simulation to illustrate the variability
of statistics calculated from random samples. Suppose there is a normal
population of size \(N=10000\), with mean \(\mu=100\) and standard
deviation \(\sigma=15\). Now we draw a sample from the population, of
size \(n=100\) \textbf{with replacement}, we can calculate sample
statistics such as mean and variance. If we further repeat the sampling
process many times, say 200, we will have 200 sets of similar sample
statistics. Let's examine these sample statistics.

The necessary parameters are already set up as below.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pop\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{10000}
\PY{n}{pop\PYZus{}mean} \PY{o}{=} \PY{l+m+mi}{100}
\PY{n}{pop\PYZus{}sd} \PY{o}{=} \PY{l+m+mi}{15}
\PY{n}{num\PYZus{}of\PYZus{}samples} \PY{o}{=} \PY{l+m+mi}{200}
\PY{n}{sample\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{100}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{questions-and-answers}{%
\subsubsection{Questions and Answers}\label{questions-and-answers}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use random seed \textbf{1234} to conduct the simulation (i.e.,
  simulate the population as specified, draw 200 samples (each of size
  100), and calculate sample mean and variance for each sample,
  respectively), evaluate the mean and standard deviation of the sample
  statistics, and compare with their theoretical values. Draw histograms
  of the sample mean and sample variance respectively.
\end{enumerate}

\textbf{REMARK 1}: Recall that, according to the Central Limit Theorem,
the sample mean
\[\bar{X} \sim  \text{N}\left(\mu, \frac{\sigma^2}{n} \right).\]

\textbf{REMARK 2}: Recall that theoretically, the sample variance
\(S^2\) satisfies
\[\text{E}[S^2] = \sigma^2, ~~ \text{Var}[S^2] = \frac{2 \sigma^4}{n - 1}, ~~\text{and } \frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}.\]

Answer:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{histograms}\PY{p}{(}\PY{n}{sample\PYZus{}mean\PYZus{}lst}\PY{p}{,} \PY{n}{sample\PYZus{}var\PYZus{}lst}\PY{p}{,} \PY{n}{pop\PYZus{}mean}\PY{p}{,} \PY{n}{pop\PYZus{}sd}\PY{p}{,} \PY{n}{sample\PYZus{}size}\PY{p}{,} \PY{n}{is\PYZus{}distribution}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{num\PYZus{}bins} \PY{o}{=} \PY{l+m+mi}{50}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{14}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}\PY{p}{:}
    
    \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{n}{figsize}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} plot sample mean}
    \PY{n}{ax1} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{121}\PY{p}{)}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{sample\PYZus{}mean\PYZus{}lst}\PY{p}{,} \PY{n}{num\PYZus{}bins}\PY{p}{,} \PY{n}{density}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sample mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sample Mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Probability Density}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Histograms of the Sample Mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} plot sample variance}
    \PY{n}{ax2} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{122}\PY{p}{)}
    \PY{n}{ax2}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{sample\PYZus{}var\PYZus{}lst}\PY{p}{,} \PY{n}{num\PYZus{}bins}\PY{p}{,} \PY{n}{density}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sample variance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sample Variance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Probability Density}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Histograms of the Sample Variance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    
    \PY{k}{if} \PY{n}{is\PYZus{}distribution}\PY{p}{:}
        \PY{c+c1}{\PYZsh{} plot theoretical distribution for figure 1}
        \PY{n}{mu}\PY{p}{,} \PY{n}{sigma} \PY{o}{=} \PY{n}{pop\PYZus{}mean}\PY{p}{,} \PY{n}{pop\PYZus{}sd}\PY{o}{/}\PY{p}{(}\PY{n}{sample\PYZus{}size}\PY{o}{*}\PY{o}{*}\PY{l+m+mf}{0.5}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{n}{mu} \PY{o}{\PYZhy{}} \PY{l+m+mi}{3} \PY{o}{*} \PY{n}{sigma}\PY{p}{,} \PY{n}{mu} \PY{o}{+} \PY{l+m+mi}{3} \PY{o}{*} \PY{n}{sigma}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{)}
        \PY{n}{y} \PY{o}{=} \PY{n}{norm}\PY{o}{.}\PY{n}{pdf}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{mu}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{sigma}\PY{p}{)}
        \PY{n}{ax1}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{theoretical distribution}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} plot theoretical distribution for figure 2}
        \PY{n}{df} \PY{o}{=} \PY{n}{sample\PYZus{}size} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}
        \PY{n}{loc} \PY{o}{=} \PY{l+m+mi}{0}
        \PY{n}{scale} \PY{o}{=} \PY{p}{(}\PY{n}{pop\PYZus{}sd}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)}\PY{o}{/}\PY{n}{df}
        \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{n}{chi2}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mf}{0.005}\PY{p}{,} \PY{n}{df}\PY{p}{,} \PY{n}{loc}\PY{p}{,} \PY{n}{scale}\PY{p}{)}\PY{p}{,}
                        \PY{n}{chi2}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mf}{0.995}\PY{p}{,} \PY{n}{df}\PY{p}{,} \PY{n}{loc}\PY{p}{,} \PY{n}{scale}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{)}
        \PY{n}{y} \PY{o}{=} \PY{n}{chi2}\PY{o}{.}\PY{n}{pdf}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{df}\PY{p}{,} \PY{n}{loc}\PY{p}{,} \PY{n}{scale}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{theoretical distribution}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
    \PY{c+c1}{\PYZsh{} set plot details}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
    \PY{n}{ax2}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
    \PY{n}{fig}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} import package}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{norm}\PY{p}{,} \PY{n}{chi2}

\PY{c+c1}{\PYZsh{} set random seed}
\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{1234}\PY{p}{)}

\PY{c+c1}{\PYZsh{} simulate the population}
\PY{n}{random\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{n}{pop\PYZus{}mean}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{pop\PYZus{}sd}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{pop\PYZus{}size}\PY{p}{)}

\PY{c+c1}{\PYZsh{} draw 200 samples and calculate the sample mean and variance for each sample}
\PY{n}{samples\PYZus{}lst} \PY{o}{=} \PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}
    \PY{n}{random\PYZus{}data}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{sample\PYZus{}size}\PY{p}{)} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}of\PYZus{}samples}\PY{p}{)}\PY{p}{]}
\PY{n}{sample\PYZus{}mean\PYZus{}lst} \PY{o}{=} \PY{p}{[}\PY{n}{sample}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{sample} \PY{o+ow}{in} \PY{n}{samples\PYZus{}lst}\PY{p}{]}
\PY{n}{sample\PYZus{}var\PYZus{}lst} \PY{o}{=} \PY{p}{[}\PY{n}{sample}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{sample} \PY{o+ow}{in} \PY{n}{samples\PYZus{}lst}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Draw histograms of the sample mean and sample variance respectively}
\PY{n}{histograms}\PY{p}{(}\PY{n}{sample\PYZus{}mean\PYZus{}lst}\PY{p}{,} \PY{n}{sample\PYZus{}var\PYZus{}lst}\PY{p}{,} \PY{n}{pop\PYZus{}mean}\PY{p}{,} \PY{n}{pop\PYZus{}sd}\PY{p}{,} \PY{n}{sample\PYZus{}size}\PY{p}{,} \PY{n}{is\PYZus{}distribution} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} for comparison, you may just report the theoretical mean/sd of the sample mean and sample variance respectively.}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Theoretical mean of the sample mean: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{pop\PYZus{}mean}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Theoretical standard deviation of the sample mean: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{pop\PYZus{}sd}\PY{o}{/}\PY{p}{(}\PY{n}{sample\PYZus{}size}\PY{o}{*}\PY{o}{*}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Theoretical mean of the sample variance: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{pop\PYZus{}sd}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Theoretical standard deviation of the sample variance: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{p}{(}\PY{p}{(}\PY{n}{pop\PYZus{}sd}\PY{o}{*}\PY{o}{*}\PY{l+m+mf}{0.5}\PY{p}{)} \PY{o}{*} \PY{p}{(}\PY{n}{pop\PYZus{}sd}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}\PY{o}{/}\PY{p}{(}\PY{n}{sample\PYZus{}size} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} overlay the theoretical distribution (not required in the assignment)}
\PY{n}{histograms}\PY{p}{(}\PY{n}{sample\PYZus{}mean\PYZus{}lst}\PY{p}{,} \PY{n}{sample\PYZus{}var\PYZus{}lst}\PY{p}{,} \PY{n}{pop\PYZus{}mean}\PY{p}{,} \PY{n}{pop\PYZus{}sd}\PY{p}{,} \PY{n}{sample\PYZus{}size}\PY{p}{,} \PY{n}{is\PYZus{}distribution} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{A0218869J--HaojunGao_files/A0218869J--HaojunGao_5_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Theoretical mean of the sample mean: 100
Theoretical standard deviation of the sample mean: 1.5
Theoretical mean of the sample variance: 225
Theoretical standard deviation of the sample variance: 8.80223487774413
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{A0218869J--HaojunGao_files/A0218869J--HaojunGao_5_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{part-ii-k-nearest-neighbor-algorithm}{%
\subsection{Part II: K-Nearest Neighbor
Algorithm}\label{part-ii-k-nearest-neighbor-algorithm}}

\hypertarget{introduction}{%
\subsubsection{Introduction}\label{introduction}}

In this assignment, we are going to experiment the K-Nearest Neighbor
(KNN) algorithm on a higher-dimensional dataset and experience the
deterioration of prediction performance as the dimensionality grows.

The experiment is built on top of the 3rd-order polynomial model:
\[y = \beta_0 + \beta_1 * x + \beta_2 * x^2 + \beta_3 * x^3 + \epsilon, ~~ \epsilon \sim \text{N}(0, \sigma^2)\]
and we are going to introduce an extra 20-dimensional predictor \(z\),
which does NOT actually play a role in generating \(y\). Yet, when in
estimation, we do not know the fact and will use both \(x\) and \(z\) as
predictors in the KNN algorithm.

\hypertarget{generation-of-the-high-dimensional-dataset}{%
\subsubsection{Generation of the high-dimensional
dataset}\label{generation-of-the-high-dimensional-dataset}}

We first simulate the 3rd-order polynomial datasets

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{c+c1}{\PYZsh{}\PYZsh{} population parameters}
\PY{n}{beta0} \PY{o}{=} \PY{l+m+mi}{1}
\PY{n}{beta1} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{2}
\PY{n}{beta2} \PY{o}{=} \PY{l+m+mi}{6}
\PY{n}{beta3} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}
\PY{n}{sigma} \PY{o}{=} \PY{l+m+mi}{2}

\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{7890}\PY{p}{)}

\PY{c+c1}{\PYZsh{}\PYZsh{} training data}
\PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mf}{0.05}\PY{p}{)}
\PY{n}{f\PYZus{}x} \PY{o}{=} \PY{n}{beta0} \PY{o}{+} \PY{n}{beta1} \PY{o}{*} \PY{n}{x} \PY{o}{+} \PY{n}{beta2} \PY{o}{*} \PY{n}{x}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2} \PY{o}{+} \PY{n}{beta3} \PY{o}{*} \PY{n}{x}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{3}
\PY{n}{epsilon} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{sigma}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
\PY{n}{y} \PY{o}{=} \PY{n}{f\PYZus{}x} \PY{o}{+} \PY{n}{epsilon}

\PY{c+c1}{\PYZsh{}\PYZsh{} test data}
\PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{5.1}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{)}
\PY{n}{f\PYZus{}x\PYZus{}test} \PY{o}{=} \PY{n}{beta0} \PY{o}{+} \PY{n}{beta1} \PY{o}{*} \PY{n}{x\PYZus{}test} \PY{o}{+} \PY{n}{beta2} \PY{o}{*} \PY{n}{x\PYZus{}test}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2} \PY{o}{+} \PY{n}{beta3} \PY{o}{*} \PY{n}{x\PYZus{}test}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{3}
\PY{n}{epsilon\PYZus{}test} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{sigma}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}\PY{p}{)}
\PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{f\PYZus{}x\PYZus{}test} \PY{o}{+} \PY{n}{epsilon\PYZus{}test}
\end{Verbatim}
\end{tcolorbox}

    The resulted training and test dataset have \textbf{100} and \textbf{51}
data points, respectively.

Next, we need to generate \(z\), the 20-dimensional predictors, of the
same sizes. Each \(z\) is a 20-dimensional multivariate normal random
variable, with mean being \((0, 0, \ldots, 0)\) and identity covariance
matrix (so that the 20 elements are independent standard normal random
variables). The resulted \(z\) is a 100*20 matrix, with each row being a
data point with 20 dimensions.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{7891}\PY{p}{)}
\PY{n}{z} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{multivariate\PYZus{}normal}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m+mi}{100}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{cov} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{identity}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
\PY{n}{z\PYZus{}test} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{multivariate\PYZus{}normal}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m+mi}{51}\PY{p}{,} \PY{n}{mean} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{cov} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{identity}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Later, we will use \((x, z)\) to predict \(y\). Let's first combine
\(x\) and \(z\) into matrices

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{59}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{train\PYZus{}x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{z}\PY{p}{)}\PY{p}{,}\PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{test\PYZus{}x} \PY{o}{=}  \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{z\PYZus{}test}\PY{p}{)}\PY{p}{,}\PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{questions-and-answers}{%
\subsubsection{Questions and Answers}\label{questions-and-answers}}

\hypertarget{for-a-fixed-k15-fit-a-knn-model-to-predict-y-with-x-z-and-measure-the-training-and-test-mse.}{%
\paragraph{\texorpdfstring{1. For a fixed \(k=15\), fit a KNN model to
predict \(y\) with \((x, z)\), and measure the training and test
MSE.}{1. For a fixed k=15, fit a KNN model to predict y with (x, z), and measure the training and test MSE.}}\label{for-a-fixed-k15-fit-a-knn-model-to-predict-y-with-x-z-and-measure-the-training-and-test-mse.}}

Answer:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{neighbors} \PY{k}{import} \PY{n}{KNeighborsRegressor}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error} \PY{k}{as} \PY{n}{mse}

\PY{c+c1}{\PYZsh{} set fixed parameter}
\PY{n}{fix\PYZus{}k} \PY{o}{=} \PY{l+m+mi}{15}

\PY{c+c1}{\PYZsh{} training model}
\PY{n}{knn} \PY{o}{=} \PY{n}{KNeighborsRegressor}\PY{p}{(}\PY{n}{n\PYZus{}neighbors}\PY{o}{=}\PY{n}{fix\PYZus{}k}\PY{p}{)}
\PY{n}{knn}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train\PYZus{}x}\PY{p}{,} \PY{n}{y}\PY{p}{)}

\PY{c+c1}{\PYZsh{} predict and measure the performance}
\PY{n}{y\PYZus{}predict} \PY{o}{=} \PY{n}{knn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}x}\PY{p}{)}
\PY{n}{mse\PYZus{}predict} \PY{o}{=} \PY{n}{mse}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}predict}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model Performance (MSE): }\PY{l+s+si}{\PYZob{}mse\PYZus{}predict\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model Performance (MSE): 32.94639319047726
    \end{Verbatim}

    \hypertarget{with-the-same-data-plot-the-training-and-test-mse-of-the-knn-model-against-k-and-find-the-optimal-k-and-the-corresponding-test-mse.}{%
\paragraph{\texorpdfstring{2. With the same data, plot the training and
test MSE of the KNN model against \(k\), and find the optimal \(k\) and
the corresponding test
MSE.}{2. With the same data, plot the training and test MSE of the KNN model against k, and find the optimal k and the corresponding test MSE.}}\label{with-the-same-data-plot-the-training-and-test-mse-of-the-knn-model-against-k-and-find-the-optimal-k-and-the-corresponding-test-mse.}}

Answer:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{94}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{train\PYZus{}model}\PY{p}{(}\PY{n}{train\PYZus{}x}\PY{p}{,} \PY{n}{test\PYZus{}x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{is\PYZus{}print} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}\PY{p}{:}
    \PY{n}{k} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{c+c1}{\PYZsh{} Initialize}
    \PY{n}{optimal\PYZus{}mse}\PY{p}{,} \PY{n}{currenct\PYZus{}mse} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}
    \PY{k}{while} \PY{n}{optimal\PYZus{}mse} \PY{o}{==} \PY{n}{currenct\PYZus{}mse}\PY{p}{:}
        \PY{c+c1}{\PYZsh{} set k for this training round}
        \PY{n}{k} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
        \PY{c+c1}{\PYZsh{} train \PYZam{} predict \PYZam{} measure}
        \PY{n}{knn} \PY{o}{=} \PY{n}{KNeighborsRegressor}\PY{p}{(}\PY{n}{n\PYZus{}neighbors}\PY{o}{=}\PY{n}{k}\PY{p}{)}
        \PY{n}{knn}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train\PYZus{}x}\PY{p}{,} \PY{n}{y}\PY{p}{)}
        \PY{n}{y\PYZus{}predict} \PY{o}{=} \PY{n}{knn}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}x}\PY{p}{)}
        \PY{n}{currenct\PYZus{}mse} \PY{o}{=} \PY{n}{mse}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}predict}\PY{p}{)}
        \PY{n}{optimal\PYZus{}mse} \PY{o}{=} \PY{n}{currenct\PYZus{}mse} \PY{k}{if} \PY{n}{currenct\PYZus{}mse} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n}{optimal\PYZus{}mse} \PY{o+ow}{or} \PY{n}{k} \PY{o}{==} \PY{l+m+mi}{1} \PY{k}{else} \PY{n}{optimal\PYZus{}mse}
        \PY{k}{if} \PY{n}{is\PYZus{}print}\PY{p}{:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Parameter k = }\PY{l+s+si}{\PYZob{}k\PYZcb{}}\PY{l+s+s1}{; Model Performance (MSE): }\PY{l+s+si}{\PYZob{}currenct\PYZus{}mse\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{k}{return} \PY{n}{k}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{optimal\PYZus{}mse}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{62}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} stop looking for the optimal k when test MSE no longer decreases as k goes up.}
\PY{n}{k}\PY{p}{,} \PY{n}{optimal\PYZus{}mse} \PY{o}{=} \PY{n}{train\PYZus{}model}\PY{p}{(}\PY{n}{train\PYZus{}x}\PY{p}{,} \PY{n}{test\PYZus{}x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Optimal k: }\PY{l+s+si}{\PYZob{}k\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Test MSE: }\PY{l+s+si}{\PYZob{}optimal\PYZus{}mse\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Parameter k = 1; Model Performance (MSE): 76.76871868226493
Parameter k = 2; Model Performance (MSE): 50.63365314897203
Parameter k = 3; Model Performance (MSE): 38.01708840946738
Parameter k = 4; Model Performance (MSE): 34.54505042921676
Parameter k = 5; Model Performance (MSE): 29.643836178903474
Parameter k = 6; Model Performance (MSE): 32.15296586511268
Optimal k: 5
Test MSE: 29.643836178903474
    \end{Verbatim}

    \hypertarget{based-on-the-analysis-above-compare-the-above-model-with-x-z-being-the-predictors-and-the-previous-model-with-x-only.-briefly-explain-why.}{%
\paragraph{\texorpdfstring{3. Based on the analysis above, compare the
above model with \((x, z)\) being the predictors and the previous model
with \(x\) only. Briefly explain
why.}{3. Based on the analysis above, compare the above model with (x, z) being the predictors and the previous model with x only. Briefly explain why.}}\label{based-on-the-analysis-above-compare-the-above-model-with-x-z-being-the-predictors-and-the-previous-model-with-x-only.-briefly-explain-why.}}

Answer:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{63}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} transfer the x and x\PYZus{}test to 2D array}
\PY{n}{train\PYZus{}x\PYZus{}only} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{test\PYZus{}x\PYZus{}only} \PY{o}{=}  \PY{n}{np}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{64}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{k}\PY{p}{,} \PY{n}{optimal\PYZus{}mse} \PY{o}{=} \PY{n}{train\PYZus{}model}\PY{p}{(}\PY{n}{train\PYZus{}x\PYZus{}only}\PY{p}{,} \PY{n}{test\PYZus{}x\PYZus{}only}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Optimal k: }\PY{l+s+si}{\PYZob{}k\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Test MSE: }\PY{l+s+si}{\PYZob{}optimal\PYZus{}mse\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Parameter k = 1; Model Performance (MSE): 8.00997691055793
Parameter k = 2; Model Performance (MSE): 5.44808287318148
Parameter k = 3; Model Performance (MSE): 5.426316500001306
Parameter k = 4; Model Performance (MSE): 4.843594490271816
Parameter k = 5; Model Performance (MSE): 4.367417625187504
Parameter k = 6; Model Performance (MSE): 4.93632176506213
Optimal k: 5
Test MSE: 4.367417625187504
    \end{Verbatim}

    \hypertarget{explaination-curse-of-dimensionality}{%
\subparagraph{Explaination: Curse of
Dimensionality}\label{explaination-curse-of-dimensionality}}

\begin{itemize}
\tightlist
\item
  The distance between neighbors is dominated by a large number of
  unrelated attributes.
\item
  In this case, instances whose values of two related attributes are
  consistent may be far apart in the 20-dimensional space.
\item
  As the result, relying on the similarity measure of these 20
  attributes can mislead the k-nearest neighbor algorithm.
\end{itemize}

    \hypertarget{we-have-seen-that-the-test-mse-is-significantly-worse-than-what-we-had-without-using-predictor-z.-to-better-understand-the-impact-of-including-irrelevant-predictors-in-the-knn-algorithm-lets-try-to-include-the-20-dimensions-of-z-one-by-one.-so-in-each-round-j-we-construct-the-predictors-by-combining-x-and-the-first-j-columns-of-z-then-repeat-the-analysis-in-question-2-and-find-the-optimal-k-and-test-mse.-at-the-end-plot-the-optimal-mse-agaist-j-and-interpret-the-result.}{%
\paragraph{\texorpdfstring{4. We have seen that the test MSE is
significantly worse than what we had without using predictor \(z\). To
better understand the impact of including irrelevant predictors in the
KNN algorithm, let's try to include the 20 dimensions of \(z\) one by
one. So in each round \(j\), we construct the predictors by combining
\(x\) and the first \(j\) columns of \(z\), then repeat the analysis in
Question 2 and find the optimal \(k\) and test MSE. At the end, plot the
optimal MSE agaist \(j\), and interpret the
result.}{4. We have seen that the test MSE is significantly worse than what we had without using predictor z. To better understand the impact of including irrelevant predictors in the KNN algorithm, let's try to include the 20 dimensions of z one by one. So in each round j, we construct the predictors by combining x and the first j columns of z, then repeat the analysis in Question 2 and find the optimal k and test MSE. At the end, plot the optimal MSE agaist j, and interpret the result.}}\label{we-have-seen-that-the-test-mse-is-significantly-worse-than-what-we-had-without-using-predictor-z.-to-better-understand-the-impact-of-including-irrelevant-predictors-in-the-knn-algorithm-lets-try-to-include-the-20-dimensions-of-z-one-by-one.-so-in-each-round-j-we-construct-the-predictors-by-combining-x-and-the-first-j-columns-of-z-then-repeat-the-analysis-in-question-2-and-find-the-optimal-k-and-test-mse.-at-the-end-plot-the-optimal-mse-agaist-j-and-interpret-the-result.}}

Answer:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{103}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{z}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
    \PY{n}{train\PYZus{}x\PYZus{}incremental} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}
        \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{z}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{n}{j}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{test\PYZus{}x\PYZus{}incremental} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}
        \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{z\PYZus{}test}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{n}{j}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{k}\PY{p}{,} \PY{n}{optimal\PYZus{}mse} \PY{o}{=} \PY{n}{train\PYZus{}model}\PY{p}{(}
        \PY{n}{train\PYZus{}x\PYZus{}incremental}\PY{p}{,} \PY{n}{test\PYZus{}x\PYZus{}incremental}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{is\PYZus{}print}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}
        \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Add first }\PY{l+s+si}{\PYZob{}j\PYZcb{}}\PY{l+s+s1}{ columns }\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{ Optimal k: }\PY{l+s+si}{\PYZob{}k\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{ Test MSE: }\PY{l+s+si}{\PYZob{}optimal\PYZus{}mse\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Add first 0 columns      Optimal k: 5    Test MSE: 4.367417625187504
Add first 1 columns      Optimal k: 5    Test MSE: 7.2142500345041976
Add first 2 columns      Optimal k: 4    Test MSE: 13.359619107018597
Add first 3 columns      Optimal k: 2    Test MSE: 15.263100962227195
Add first 4 columns      Optimal k: 5    Test MSE: 16.674825717732034
Add first 5 columns      Optimal k: 2    Test MSE: 17.879872756941463
Add first 6 columns      Optimal k: 2    Test MSE: 24.436585793561473
Add first 7 columns      Optimal k: 5    Test MSE: 22.42699951576807
Add first 8 columns      Optimal k: 2    Test MSE: 26.47237779960154
Add first 9 columns      Optimal k: 8    Test MSE: 24.642352439593413
Add first 10 columns     Optimal k: 7    Test MSE: 23.370264787676305
Add first 11 columns     Optimal k: 6    Test MSE: 21.906956923650522
Add first 12 columns     Optimal k: 4    Test MSE: 25.543163075510957
Add first 13 columns     Optimal k: 6    Test MSE: 27.054482241553522
Add first 14 columns     Optimal k: 7    Test MSE: 24.069530259757233
Add first 15 columns     Optimal k: 7    Test MSE: 23.60896179380117
Add first 16 columns     Optimal k: 4    Test MSE: 27.17057594236693
Add first 17 columns     Optimal k: 5    Test MSE: 26.178734436435576
Add first 18 columns     Optimal k: 6    Test MSE: 32.814828831731226
Add first 19 columns     Optimal k: 3    Test MSE: 31.48016670629021
Add first 20 columns     Optimal k: 5    Test MSE: 29.643836178903474
    \end{Verbatim}

    \hypertarget{explaination-curse-of-dimensionality}{%
\subparagraph{Explaination: Curse of
Dimensionality}\label{explaination-curse-of-dimensionality}}

\begin{itemize}
\tightlist
\item
  Result basically follows: the more unrelated dimensions added, the
  worse the model's performance.
\item
  The KNN's rationale is that using sample's neighbours(using distance
  to measure) to represent itself in that similar samples are more
  likely to be the same category.
\item
  The above result shows that unrelated dimensions undermine the process
  of defining the neighbor, in other words, the similarity between
  samples is more difficult to describe with distance.
\end{itemize}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
